# LLMStart Module 2 - Telegram LLM-ассистент

Telegram-бот для первичной консультации клиентов по IT-услугам с использованием LLM. Реализован по принципу KISS (Keep It Simple, Stupid) для быстрой проверки гипотезы.

## Функциональность

- **Диалог с клиентами**: Автоматическая квалификация потребностей через 4 вопроса
- **LLM-рекомендации**: Персонализированные предложения услуг на основе ответов
- **Сбор контактов**: Автоматическое сохранение лидов в CSV
- **Обработка ошибок**: Fallback при недоступности LLM
- **Возвратные пользователи**: Продолжение незавершенных диалогов

## Технологии

- **Python 3.11** + aiogram (long polling)
- **OpenAI-совместимый API** (локальные: ollama, LM Studio; облачные: OpenRouter)
- **CSV-хранилище** лидов (без БД)
- **Конфигурация** через `.env`

## Быстрый старт

### 1. Настройка окружения
```powershell
# Создание venv и установка зависимостей
./setup.ps1

# Настройка переменных окружения
# Скопируйте config/env.examples в .env и заполните:
# - TELEGRAM_BOT_TOKEN (получить у @BotFather)
# - LLM_BASE_URL (например: http://localhost:11434/v1)
# - LLM_API_KEY (ваш API ключ)
# - LLM_MODEL (например: llama3:8b-instruct)
```

### 2. Запуск бота
```powershell
./run.ps1
```

### 3. Тестирование
- Отправьте `/ping` → получите "pong"
- Отправьте `/start` → начнется диалог-консультация
- Отправьте `/ask <вопрос>` → получите ответ от LLM

## Структура проекта

```
bot/
├── main.py          # Точка входа, запуск long polling
├── handlers.py      # Обработчики команд и диалогов
├── llm_client.py    # OpenAI-совместимый клиент
├── prompt.py        # Системный промпт и шаблоны
├── lead_store.py    # Сохранение лидов в CSV
└── logging_conf.py  # Настройка логирования

config/
└── env.examples     # Пример переменных окружения

doc/
├── product_idea.md  # Идея продукта и сценарии
├── vision.md        # Техническое видение (KISS)
├── tasklist.md      # Итерационный план разработки
├── conventions.md   # Конвенции разработки
└── workflow.md      # Процесс разработки
```

## Команды бота

- `/start` — начать консультацию (новый диалог или продолжить)
- `/ping` — проверка работоспособности
- `/ask <вопрос>` — задать вопрос LLM напрямую
- `/reset` — сбросить текущий диалог

## Сценарий работы

1. **Приветствие**: Бот знакомится и выясняет потребность
2. **Квалификация**: 4 вопроса о бюджете, сроках, приоритетах
3. **Рекомендация**: LLM формирует персонализированное предложение
4. **Сбор контакта**: Запрос и сохранение контактных данных
5. **Сохранение лида**: Запись в CSV для дальнейшей обработки

## Конфигурация

Все настройки в файле `.env`:

```env
# Обязательные
TELEGRAM_BOT_TOKEN=your_bot_token
LLM_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=your_api_key

# Опциональные
LLM_MODEL=llama3:8b-instruct
```

## Документация

- `doc/product_idea.md` — идея продукта, цели, сценарии
- `doc/vision.md` — техническое видение и архитектура
- `doc/tasklist.md` — план разработки и прогресс
- `doc/conventions.md` — правила написания кода
- `doc/workflow.md` — процесс разработки

## Лицензия

См. файл `LICENSE` в корне репозитория.


